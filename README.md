# Haris Naeem

**Building MIT-licensed, offline-first, privacy-friendly LLM tools for everyday use.**

---

### What I do
- Develop **browser-based LLM apps** that run entirely on the client (no servers, no tracking).
- Package **ultra-light open LLMs** to run smoothly on modest hardware.
- Create **task-specific tools** (e.g. translator, summarizer, document Q&A) designed for offline use.
- Publish everything under **MIT license** so others can freely reuse and build upon it.

### Principles
- **Privacy-first:** tools should work offline without sending data anywhere.  
- **Accessible:** usable on everyday devices without heavy GPUs or cloud.  
- **Simple deploys:** static hosting or local use ‚Äî no complicated infra.  
- **Open by default:** all code permissively licensed.  

### Current focus
- Building **ready-to-use translators** that run entirely in-browser.  
- Exploring **everyday AI tools** (summarization, note rewriting, language Q&A).  
- Documenting clear, reproducible **how-to-run** guides for non-technical users.  

### Tech stack
- [`transformers.js`](https://github.com/xenova/transformers.js) & WebAssembly (SIMD)  
- Web Workers & browser-native APIs  
- Quantized LLMs (GGUF, llama.cpp ecosystem)  
- Model Context Protocol (MCP) for local integrations  

---

### Beyond coding
When I‚Äôm not building, I‚Äôm usually outdoors ‚Äî  
I play basketball & football (often with kids!) and can spin a basketball on my thumb üèÄüëç.


## Contact

For more information and links to my social profiles, visit my [Linktree](https://harisnae.github.io)
